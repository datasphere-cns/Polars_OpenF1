{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df9ec18",
   "metadata": {},
   "source": [
    "# Polars vs Pandas\n",
    "\n",
    "**Autor:** Nelson Zepeda  \n",
    "**Correo:** nelson.zepeda@datasphere.tech\n",
    "\n",
    "**Empresa:** [datasphere.tech](https://datasphere.tech)  \n",
    "**LinkedIn:** [Datasphere Consulting](https://www.linkedin.com/company/datasphere-consulting/)  \n",
    "**Fecha:** octubre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadfa1ea",
   "metadata": {},
   "source": [
    "# Polars: que es, desde cuando existe y por que usarlo\n",
    "\n",
    "**Que es**  \n",
    "Polars (https://pola.rs) es una libreria de DataFrames orientada a columnas, escrita en **Rust** con API para **Python**. Usa el formato de memoria de **Apache Arrow**, lo que permite operaciones vectorizadas, bajo overhead y compatibilidad con otros sistemas.\n",
    "\n",
    "**Desde cuando esta disponible**  \n",
    "El proyecto comenzo a publicarse alrededor de **2020** y gano adopcion amplia en **2022**. A partir de **2024** se consolida con lanzamientos 1.x y un ecosistema mas maduro (documentacion, motores lazy estables y conectores de E/S).\n",
    "\n",
    "## Caracteristicas principales\n",
    "\n",
    "- **Nucleo en Rust**: ejecucion muy rapida, paralelismo multi-hilo y sin GIL.\n",
    "- **Modelo columnar (Arrow)**: operaciones vectorizadas, menor uso de memoria y zero-copy cuando es posible.\n",
    "- **Dos modos de trabajo**:\n",
    "  - **Eager**: estilo parecido a pandas para tareas interactivas.\n",
    "  - **Lazy**: construye un plan de consulta optimizado antes de ejecutar.\n",
    "- **Optimizador de consultas (lazy)**:\n",
    "  - *Projection pushdown*: solo lee las columnas necesarias.\n",
    "  - *Predicate pushdown*: aplica filtros lo mas cerca posible de la fuente.\n",
    "  - *Pipeline fusion*: combina pasos para reducir materializaciones intermedias.\n",
    "- **Streaming / out-of-core**: procesa archivos grandes sin cargarlos completos a memoria.\n",
    "- **I/O rapido**: `scan_csv`, `scan_parquet`, `read_csv`, `read_parquet` con lectura paralela.\n",
    "- **Funciones potentes**: `group_by`, `join`, `sort`, `window functions`, `pivot/unpivot`, expresiones vectorizadas.\n",
    "- **Tipos ricos**: numericos, boolean, string UTF8, datetime (con zonas horarias), duration, categorical, listas y estructuras.\n",
    "- **Interoperabilidad**: conversion con **pandas**, **NumPy** y **PyArrow**.\n",
    "- **Facil de instalar**: `pip install polars`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d10a5",
   "metadata": {},
   "source": [
    "## Polars vs Pandas\n",
    "\n",
    "| Aspecto | Polars | Pandas | Nota clave |\n",
    "|---|---|---|---|\n",
    "| Motor | Rust + Arrow | C/NumPy + Python | Polars aprovecha paralelismo nativo. |\n",
    "| Modos de ejecucion | Eager y **Lazy** (plan optimizado) | Eager | Lazy aplica predicate/projection pushdown y fusiona pasos. |\n",
    "| Paralelismo | Multi-hilo por defecto | Mayormente un solo hilo | Pandas 2.x mejora con copy-on-write pero no es multihilo. |\n",
    "| Modelo de memoria | Columnar (Arrow) | Basado en NumPy | Columnar favorece escaneo, agregaciones y E/S. |\n",
    "| E/S CSV/Parquet | `scan_csv`, `scan_parquet` con pushdown y streaming | `read_csv`, `read_parquet` | Polars suele leer mas rapido y con menos RAM. |\n",
    "| GroupBy/Join/Sort | Muy rapido y paralelo | Solido, pero generalmente mas lento a gran escala | Ventaja de Polars crece con millones de filas. |\n",
    "| Tipos de datos | Numericos, boolean, string UTF8, datetime con tz, duration, categorical, list, struct | Amplios; pd.NA, Arrow opcional en algunas rutas | Ambos maduros; Polars estricta en dtypes. |\n",
    "| Falta de valores | `null` (y NaN para floats) | `NaN`/`pd.NA` segun dtype | Diferencias sutiles en comparaciones y agregaciones. |\n",
    "| UDFs | Expresiones vectorizadas; UDFs Python existen pero menos necesarias | UDFs via `apply` frecuentes | Evitar `apply` en pandas por performance. |\n",
    "| Ecosistema ML | Interopera via pandas/NumPy | Integracion directa y masiva | scikit-learn espera pandas/NumPy. |\n",
    "\n",
    "## Cuando elegir cada uno\n",
    "\n",
    "- **Elige Polars si**:\n",
    "  - Necesitas pipelines eficientes de E/S -> filtrado -> agregacion -> join.\n",
    "  - Quieres ejecutar en paralelo y optimizar automaticamente con **lazy**.\n",
    "  - Debes procesar archivos mas grandes que la RAM usando **streaming**.\n",
    "\n",
    "- **Elige Pandas si**:\n",
    "  - Tu flujo depende de librerias que consumen pandas directamente.\n",
    "  - Tu data cabe comodamente en memoria y prima la compatibilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46657f45",
   "metadata": {},
   "source": [
    "# Pandas vs Polars: benchmark de operaciones\n",
    "\n",
    "Esta seccion inicial define el **proposito del benchmark** y carga las **dependencias** necesarias para medir y comparar operaciones tipicas entre **pandas** y **polars** (filtro, agregaciones, joins y ordenamientos) sobre datasets de gran tamaño.\n",
    "\n",
    "## Objetivo\n",
    "Medir tiempos de ejecucion de operaciones tabulares representativas, manteniendo condiciones justas (mismas entradas, mismo hardware y metrica de tiempo consistente) para comparar el rendimiento de pandas y polars.\n",
    "\n",
    "## Alcance\n",
    "- Enfocado en **procesamiento** (no en visualizacion).\n",
    "- Incluye operaciones vectorizadas comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Pandas vs Polars: benchmark de operaciones\n",
    "# ==========================================\n",
    "import time\n",
    "import os\n",
    "import statistics as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7919b",
   "metadata": {},
   "source": [
    "#### Datos base (generación y estructura)\n",
    "\n",
    "- Define el **tamaño del dataset**: `N = 5_000_000` filas para forzar una carga de trabajo donde se aprecian diferencias reales de rendimiento.\n",
    "- Crea un **generador aleatorio reproducible**: `rng = np.random.default_rng(42)` fija la semilla (42) para que los resultados sean comparables entre corridas.\n",
    "- Genera **cuatro columnas** con distintas distribuciones y tipos:\n",
    "  - `cat`: enteros **[0, 1000)** con `dtype=np.int32` (sirve como categoría/clave para `groupby` y `join`).\n",
    "  - `x1`: distribución **normal** (media 0, sd 1) en `float64`.\n",
    "  - `x2`: enteros **[0, 10_000)** con `dtype=np.int32` (útil para agregaciones y filtros modulares).\n",
    "  - `x3`: distribución **uniforme** en `[0, 1)`, `float64`.\n",
    "- Construye dos DataFrames **idénticos en contenido**:\n",
    "  - `pdf` con **pandas**.\n",
    "  - `pldf` con **polars**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Base de Datos ----------\n",
    "N = 5_000_000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "cat = rng.integers(0, 1_000, N, dtype=np.int32)\n",
    "x1  = rng.normal(0, 1, N)\n",
    "x2  = rng.integers(0, 10_000, N, dtype=np.int32)\n",
    "x3  = rng.random(N)\n",
    "\n",
    "pdf = pd.DataFrame({\"cat\": cat, \"x1\": x1, \"x2\": x2, \"x3\": x3})\n",
    "pldf = pl.DataFrame({\"cat\": cat, \"x1\": x1, \"x2\": x2, \"x3\": x3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48c63d",
   "metadata": {},
   "source": [
    "#### Dimension para join\n",
    "\n",
    "- Simula una **dimension** de un esquema estrella y se une contra la tabla de **hechos** grande creada antes (`pdf`/`pldf`, con 5M de filas).\n",
    "- El join es **muchos-a-uno**: muchas filas del hecho por cada categoria `cat` en la dimension.\n",
    "- Permite medir rendimiento en **join + ordenamientos** (p. ej., ordenar por `w` y tomar top-k) con una clave que **siempre existe** en la tabla de hechos, ya que `cat` en los datos base fue generado en el rango `0..999`.\n",
    "\n",
    "- Define el tamano de la **tabla de dimension**: `dim_size = 1_000`.\n",
    "- Crea un DataFrame **pandas** `dim` con:\n",
    "  - `cat`: valores enteros `0..999` (`np.arange(dim_size, dtype=np.int32)`) que actuan como **llave**.\n",
    "  - `w`: una columna de **pesos aleatorios** `rng.random(dim_size)` usada luego para ordenar o calcular top-k.\n",
    "- Convierte esa misma tabla a **polars** con `pl.from_pandas(dim)` para garantizar que **pandas y polars** operen sobre **los mismos datos** en los benchmarks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión para join\n",
    "dim_size = 1_000\n",
    "dim = pd.DataFrame({\"cat\": np.arange(dim_size, dtype=np.int32),\n",
    "                    \"w\": rng.random(dim_size)})\n",
    "pldim = pl.from_pandas(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb884d",
   "metadata": {},
   "source": [
    "#### Helpers: `bench` y `show`\n",
    "\n",
    "##### `bench(fn, repeats=5, warmup=1)`\n",
    "Mide el tiempo de ejecución de una función `fn` varias veces y devuelve estadísticas resumidas.\n",
    "\n",
    "- **Warm-up**: ejecuta `fn()` `warmup` veces **sin medir** para “calentar” caches/JIT/IO y estabilizar el entorno.\n",
    "- **Medición**: usa `time.perf_counter()` (reloj de alta resolución) para cronometrar `repeats` ejecuciones.\n",
    "- **Salida**: retorna un `dict` con `median`, `mean`, `min`, `max` en segundos (redondeados a 4 decimales).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91648f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- helpers ----------\n",
    "def bench(fn, repeats=5, warmup=1):\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    t = []\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = fn()\n",
    "        t1 = time.perf_counter()\n",
    "        t.append(t1 - t0)\n",
    "    return dict(\n",
    "        median=round(stats.median(t), 4),\n",
    "        mean=round(stats.mean(t), 4),\n",
    "        min=round(min(t), 4),\n",
    "        max=round(max(t), 4),\n",
    "    )\n",
    "\n",
    "def show(name, res):\n",
    "    print(f\"{name:24s}  median={res['median']}s  mean={res['mean']}s  \"\n",
    "          f\"min={res['min']}s  max={res['max']}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb1722",
   "metadata": {},
   "source": [
    "#### 1) Filtro + columna derivada\n",
    "\n",
    "**Propósito.**  \n",
    "Medir el tiempo de una transformación típica: **filtrar** filas y **crear** una columna calculada.\n",
    "Filtramos las filas donde x1 es positivo y x2 es múltiplo de 7; luego calculamos un puntaje y = x1 * log(1 + x2) + x3 ( x1 pesa, log(1+x2) suaviza, x3 ajusta).\n",
    "\n",
    "**Regla de negocio aplicada**\n",
    "- Filtro: `x1 > 0` **y** `x2 % 7 == 0` (múltiplos de 7).\n",
    "- Columna nueva: `y = x1 * log1p(x2) + x3`.  \n",
    "  - En pandas se usa `np.log1p(x2)` (estable y preciso cuando `x2` es grande).  \n",
    "  - En polars se usa `(x2 + 1).log()`, que es equivalente a `log1p`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f350b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1) Filtro + columna derivada ----------\n",
    "# regla: x1 > 0 & x2 % 7 == 0; nueva y = x1 * log1p(x2) + x3\n",
    "import math\n",
    "\n",
    "pandas_filter = lambda: (\n",
    "    (lambda df: df.assign(y=df[\"x1\"] * np.log1p(df[\"x2\"]) + df[\"x3\"]))(\n",
    "        pdf.loc[(pdf[\"x1\"] > 0) & (pdf[\"x2\"].mod(7).eq(0))]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "polars_filter_eager = lambda: (\n",
    "    pldf.filter( (pl.col(\"x1\") > 0) & (pl.col(\"x2\") % 7 == 0) )\n",
    "        .with_columns( (pl.col(\"x1\") * (pl.col(\"x2\")+1).log() + pl.col(\"x3\"))\n",
    "                       .alias(\"y\") )\n",
    ")\n",
    "\n",
    "polars_filter_lazy = lambda: (\n",
    "    pldf.lazy()\n",
    "        .filter( (pl.col(\"x1\") > 0) & (pl.col(\"x2\") % 7 == 0) )\n",
    "        .with_columns( (pl.col(\"x1\") * (pl.col(\"x2\")+1).log() + pl.col(\"x3\"))\n",
    "                       .alias(\"y\") )\n",
    "        .collect()\n",
    ")\n",
    "\n",
    "print(\"\\n# 1) Filtro + columna derivada\")\n",
    "show(\"pandas\", bench(pandas_filter))\n",
    "show(\"polars eager\", bench(polars_filter_eager))\n",
    "show(\"polars lazy\", bench(polars_filter_lazy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10694596",
   "metadata": {},
   "source": [
    "#### 2) Groupby / Aggregations\n",
    "\n",
    "**Qué hace**  \n",
    "Agrupa el DataFrame por la columna **`cat`** y calcula, por grupo:\n",
    "- `mean(x1)` → promedio de `x1`\n",
    "- `sum(x2)`  → suma de `x2`\n",
    "- `max(x3)`  → máximo de `x3`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) Groupby/agg ----------\n",
    "# por cat: mean(x1), sum(x2), max(x3)\n",
    "pandas_gb = lambda: pdf.groupby(\"cat\", sort=False, observed=True).agg({\n",
    "    \"x1\": \"mean\",\n",
    "    \"x2\": \"sum\",\n",
    "    \"x3\": \"max\"\n",
    "}).reset_index()\n",
    "\n",
    "polars_gb_eager = lambda: (\n",
    "    pldf.group_by(\"cat\")\n",
    "        .agg( pl.col(\"x1\").mean(),\n",
    "              pl.col(\"x2\").sum(),\n",
    "              pl.col(\"x3\").max() )\n",
    ")\n",
    "\n",
    "polars_gb_lazy = lambda: (\n",
    "    pldf.lazy()\n",
    "        .group_by(\"cat\")\n",
    "        .agg( pl.col(\"x1\").mean(),\n",
    "              pl.col(\"x2\").sum(),\n",
    "              pl.col(\"x3\").max() )\n",
    "        .collect()\n",
    ")\n",
    "\n",
    "print(\"\\n# 2) Groupby/Aggregations\")\n",
    "show(\"pandas\", bench(pandas_gb))\n",
    "show(\"polars eager\", bench(polars_gb_eager))\n",
    "show(\"polars lazy\", bench(polars_gb_lazy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7c421",
   "metadata": {},
   "source": [
    "#### 3) Join + Top-K\n",
    "\n",
    "**Qué hace**\n",
    "1. **Enriquece** la tabla grande (`pdf`/`pldf`) con la **dimensión** `dim/pldim` por la clave `cat` mediante un **left join**.\n",
    "2. **Ordena** todas las filas resultantes por la columna `w` en **orden descendente**.\n",
    "3. **Toma las 10 primeras filas** tras ese orden.  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) Join + top-k ----------\n",
    "# join con dim en cat; luego top 10 por w descendente dentro de cada cat (sample)\n",
    "pandas_join_topk = lambda: (\n",
    "    pdf.merge(dim, on=\"cat\", how=\"left\")\n",
    "       .sort_values(\"w\", ascending=False)\n",
    "       .head(10)\n",
    ")\n",
    "\n",
    "polars_join_topk_eager = lambda: (\n",
    "    pldf.join(pldim, on=\"cat\", how=\"left\")\n",
    "        .sort(\"w\", descending=True)\n",
    "        .head(10)\n",
    ")\n",
    "\n",
    "polars_join_topk_lazy = lambda: (\n",
    "    pldf.lazy().join(pldim.lazy(), on=\"cat\", how=\"left\")\n",
    "        .sort(\"w\", descending=True)\n",
    "        .limit(10)\n",
    "        .collect()\n",
    ")\n",
    "\n",
    "print(\"\\n# 3) Join + Top-K\")\n",
    "show(\"pandas\", bench(pandas_join_topk))\n",
    "show(\"polars eager\", bench(polars_join_topk_eager))\n",
    "show(\"polars lazy\", bench(polars_join_topk_lazy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12863e",
   "metadata": {},
   "source": [
    "#### 4) Sort global + selección de columnas\n",
    "\n",
    "Ordena **todo** el DataFrame por dos claves y luego se queda solo con `[\"cat\",\"x1\",\"x2\"]`:\n",
    "\n",
    "- Clave 1: `x1` **descendente** (mayores primero).\n",
    "- Clave 2: `x2` **ascendente** (desempate).\n",
    "- Selección final: descarta `x3`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4) Sort global + selección de columnas ----------\n",
    "pandas_sort = lambda: pdf.sort_values([\"x1\",\"x2\"], ascending=[False, True])[[\"cat\",\"x1\",\"x2\"]]\n",
    "polars_sort_eager = lambda: pldf.sort([\"x1\",\"x2\"], descending=[True, False]).select([\"cat\",\"x1\",\"x2\"])\n",
    "polars_sort_lazy = lambda: pldf.lazy().sort([\"x1\",\"x2\"], descending=[True, False]).select([\"cat\",\"x1\",\"x2\"]).collect()\n",
    "\n",
    "print(\"\\n# 4) Sort + select\")\n",
    "show(\"pandas\", bench(pandas_sort))\n",
    "show(\"polars eager\", bench(polars_sort_eager))\n",
    "show(\"polars lazy\", bench(polars_sort_lazy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a28083",
   "metadata": {},
   "source": [
    "#### 5) Lectura de CSV grande (I/O): pandas vs polars\n",
    "\n",
    "- Genera (si no existe) un archivo **CSV sintético** con `N = 5_000_000` filas y 4 columnas numéricas (`cat`, `x1`, `x2`, `x3`) para tener un caso de lectura realista y pesado.\n",
    "- **Mide el tiempo** de lectura del mismo archivo con:\n",
    "  - `pandas.read_csv(...)`\n",
    "  - `polars.read_csv(...)`\n",
    "- Imprime **duración** y **shape** resultante para cada librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Benchmark de lectura de CSV grande: pandas vs polars ----\n",
    "# Genera un CSV sintético y mide tiempos de lectura.\n",
    "N = 5_000_000  \n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Genera un CSV si no existe\n",
    "csv_path = \"synth.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    pdf = pd.DataFrame({\n",
    "        \"cat\": rng.integers(0, 10_000, N, dtype=np.int32),\n",
    "        \"x1\":  rng.normal(0, 1, N),\n",
    "        \"x2\":  rng.integers(0, 1_000_000, N, dtype=np.int32),\n",
    "        \"x3\":  rng.random(N),\n",
    "    })\n",
    "    pdf.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee con pandas\n",
    "t0 = time.perf_counter()\n",
    "pdf = pd.read_csv(csv_path)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"pandas read_csv: {t1 - t0:.2f}s, shape={pdf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee con polars (multihilo, streaming desactivado)\n",
    "t0 = time.perf_counter()\n",
    "pldf = pl.read_csv(csv_path)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"polars read_csv: {t1 - t0:.2f}s, shape={pldf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54555af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dtypes explícitos para saltarte el costo de inferir el schema.\n",
    "dtypes = {\"cat\": pl.Int32, \"x1\": pl.Float64, \"x2\": pl.Int32, \"x3\": pl.Float64}\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "pldf = pl.read_csv(csv_path, dtypes=dtypes)  # usa todos los núcleos por defecto\n",
    "t1 = time.perf_counter()\n",
    "print(f\"polars read_csv (dtypes): {t1 - t0:.2f}s, shape={pldf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a599505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa el motor lazy para aplicar \"projection pushdown\" y procesar en streaming.\n",
    "dtypes = {\"cat\": pl.Int32, \"x1\": pl.Float64, \"x2\": pl.Int32, \"x3\": pl.Float64}\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "pldf = (\n",
    "    pl.scan_csv(csv_path, dtypes=dtypes)    # no carga todo a memoria al inicio\n",
    "      .select([\"cat\", \"x2\"])                # solo las columnas que necesitas\n",
    "      .collect(streaming=True)              # pipeline en streaming y multihilo\n",
    ")\n",
    "t1 = time.perf_counter()\n",
    "print(f\"polars scan_csv->select (stream): {t1 - t0:.2f}s, shape={pldf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4883769",
   "metadata": {},
   "source": [
    "## Conclusiones del benchmark (Pandas vs Polars)\n",
    "\n",
    "## Resultados clave\n",
    "- **Lectura CSV (I/O)**: pasaste de `pandas read_csv: 3.20s` (shape=(5,000,000, 4)) a  \n",
    "  `polars scan_csv→select (stream): 0.28s` (shape=(5,000,000, 2)).  \n",
    "  → **~11.4× más rápido**, aprovechando **lazy + streaming** y **projection pushdown** (solo 2 columnas).\n",
    "\n",
    "- **Transformaciones (filtro, groupby, join, sort)**: Polars (especialmente en **modo lazy**) consistentemente superó a Pandas en datasets grandes por:\n",
    "  - **Paralelismo** multi-hilo en Rust.\n",
    "  - **Optimización de plan** (predicate/projection pushdown, pipeline fusion).\n",
    "  - **Modelo columnar (Arrow)** que favorece escaneos y agregaciones.\n",
    "\n",
    "- **Creación de DataFrames desde NumPy**: puede verse **más rápida en Pandas** (casi zero-copy). No contradice lo anterior: la ventaja de Polars aparece en **procesamiento** e **I/O** a escala.\n",
    "\n",
    "## Qué significa en la práctica\n",
    "- Si tu pipeline es **E/S → filtros → selección de columnas → agregaciones/joins**, Polars te dará **2–10×** de mejora (o más) y **menos RAM**.\n",
    "- El patrón **`scan_csv().filter().select().collect(streaming=True)`** es decisivo: evita parsear/traer datos innecesarios.\n",
    "- En Pandas, para acercarte, debes recurrir a patrones manuales (p. ej., `read_csv(..., usecols=..., chunksize=...)`), con más código y aún así, típicamente, menor rendimiento.\n",
    "\n",
    "## Recomendaciones operativas\n",
    "1. **Usa Polars Lazy por defecto** para pipelines: `scan_* → filter → select → group_by → collect(streaming=True)`.\n",
    "2. **Declara `dtypes`** al leer CSV si conoces el schema (evita la inferencia).\n",
    "3. **Lee solo lo necesario** (`select`) y **filtra al escanear** (`filter`) para reducir I/O y memoria.\n",
    "4. **Para top-k**, usa `sort(...).limit(k)` o APIs específicas (`top_k`) en lugar de ordenar todo.\n",
    "5. **Interoperabilidad**: convierte a Pandas solo cuando un paquete lo exija (`df.to_pandas()`), al final del pipeline.\n",
    "\n",
    "## Cuándo seguir con Pandas\n",
    "- Ecosistema que **requiere directamente Pandas/NumPy** (modelos ML, ciertos gráficos).\n",
    "- Tareas pequeñas/interactivas donde la diferencia de rendimiento **no justifica** el cambio.\n",
    "\n",
    "## Resumen\n",
    "- **Polars** es la opción preferida para **datasets medianos/grandes** y **pipelines analíticos**: más rápido, eficiente y declarativo.\n",
    "- **Pandas** mantiene su lugar como **interfaz universal** en el ecosistema Python, ideal para integración.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
